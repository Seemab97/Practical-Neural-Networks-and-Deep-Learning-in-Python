{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2488a19793be4457b8d5ec0d0826fe4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38021d15612d4d45b79f7b3a3c85a9d8",
              "IPY_MODEL_b5ef9b5a4afd48bfa1ba2f91de3bad79",
              "IPY_MODEL_863edaf890414a9ca66c3212123ca4dd"
            ],
            "layout": "IPY_MODEL_f08752f1d1cc44ee80ec805740d9a325"
          }
        },
        "38021d15612d4d45b79f7b3a3c85a9d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed564f95f14a4885b2ae0342ffc02b8a",
            "placeholder": "​",
            "style": "IPY_MODEL_a9d13c4a52064a9989dcc913f60e9450",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "b5ef9b5a4afd48bfa1ba2f91de3bad79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c196487e8b674b4f9f3afd9eb4749c85",
            "max": 2324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75f8940b20f640caa27e07a6175fe3de",
            "value": 2324
          }
        },
        "863edaf890414a9ca66c3212123ca4dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0907f99038d4e40b8b598e649ed3f80",
            "placeholder": "​",
            "style": "IPY_MODEL_8203e0821b0f4002b7dfafb8586c9f39",
            "value": " 2.32k/2.32k [00:00&lt;00:00, 137kB/s]"
          }
        },
        "f08752f1d1cc44ee80ec805740d9a325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed564f95f14a4885b2ae0342ffc02b8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9d13c4a52064a9989dcc913f60e9450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c196487e8b674b4f9f3afd9eb4749c85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75f8940b20f640caa27e07a6175fe3de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0907f99038d4e40b8b598e649ed3f80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8203e0821b0f4002b7dfafb8586c9f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a2aeda3399a4cdeb0a6f3ebb578669f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d74d10517694451aa8ead2f9a817a0f7",
              "IPY_MODEL_12a12a7e39904156a4520e4dd48b0186",
              "IPY_MODEL_057bb92c40784dbe967547355a136a00"
            ],
            "layout": "IPY_MODEL_0c9127c8c66844c3b35157d5486a7f45"
          }
        },
        "d74d10517694451aa8ead2f9a817a0f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08e2f63c1cdc44308095018fe402ec10",
            "placeholder": "​",
            "style": "IPY_MODEL_90a981422f7c434c952ce0f474159955",
            "value": "Downloading (…)ve/main/spiece.model: 100%"
          }
        },
        "12a12a7e39904156a4520e4dd48b0186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b93dc2f6c394de9bb2319400b83163d",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abab8023fcd946cd946e4484ca0c4a38",
            "value": 791656
          }
        },
        "057bb92c40784dbe967547355a136a00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a84edb609fe463c9ca5ccd21d1f2bce",
            "placeholder": "​",
            "style": "IPY_MODEL_8d0b6a6f4b3447cab497755433545b40",
            "value": " 792k/792k [00:00&lt;00:00, 7.07MB/s]"
          }
        },
        "0c9127c8c66844c3b35157d5486a7f45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08e2f63c1cdc44308095018fe402ec10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90a981422f7c434c952ce0f474159955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b93dc2f6c394de9bb2319400b83163d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abab8023fcd946cd946e4484ca0c4a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a84edb609fe463c9ca5ccd21d1f2bce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d0b6a6f4b3447cab497755433545b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58160ffe21664fb4a9d1442c8d330826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef3e397537b34ac7803f6c30d2b1b9cd",
              "IPY_MODEL_277b6d7c11a2423fa821769ef9b89249",
              "IPY_MODEL_2498a44bfd304c05976f913b9cb08214"
            ],
            "layout": "IPY_MODEL_8dbc4f43cec74122b97796d6a7394d54"
          }
        },
        "ef3e397537b34ac7803f6c30d2b1b9cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08309ea9c6ec4eb79e46fa24ca3d9fe3",
            "placeholder": "​",
            "style": "IPY_MODEL_9116000cb20a40ed817fe8846df49f70",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "277b6d7c11a2423fa821769ef9b89249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1abb65bd2c414b80b6617ca836562092",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_612f26a615e641f79c5031b92f3a2117",
            "value": 1389353
          }
        },
        "2498a44bfd304c05976f913b9cb08214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f57a62547fc34e41948f968ca4555ae5",
            "placeholder": "​",
            "style": "IPY_MODEL_2abdab7994bb446bafb30a3cf6cee4ab",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 17.7MB/s]"
          }
        },
        "8dbc4f43cec74122b97796d6a7394d54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08309ea9c6ec4eb79e46fa24ca3d9fe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9116000cb20a40ed817fe8846df49f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1abb65bd2c414b80b6617ca836562092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "612f26a615e641f79c5031b92f3a2117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f57a62547fc34e41948f968ca4555ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2abdab7994bb446bafb30a3cf6cee4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seemab97/Practical-Neural-Networks-and-Deep-Learning-in-Python/blob/main/Tokenization_T5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Doing this to get the data\n",
        "# Mount Google Drive to this Notebook instance.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOR8uouu0NGi",
        "outputId": "82acbda7-6759-4828-e255-cb1ea8bd144c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nbrvUWdzxc7",
        "outputId": "49ec94f6-bfed-4133-9d8e-92ec6a0eeec2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOBizHfLz23D",
        "outputId": "f5ab0c2e-fea7-40a7-c480-07a2865af58c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch"
      ],
      "metadata": {
        "id": "dwQRYuhYz8Cs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading Data from file"
      ],
      "metadata": {
        "id": "bVMp5dbrqcie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1/4th of data\n",
        "new_file_path = '/content/drive/MyDrive/Internship/Meetup - Text Data/quarter_context_train.json'"
      ],
      "metadata": {
        "id": "smXf8Uk60Da2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data from the JSON file\n",
        "with open(new_file_path, 'r') as json_file:\n",
        "    data = json.load(json_file)"
      ],
      "metadata": {
        "id": "gQOXsnno0Hdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc2rOZZC0kn6",
        "outputId": "d45b30c3-8e75-4aef-a0b6-97eeaf75785a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2075"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[2074]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdbhjngF0m_W",
        "outputId": "159034ce-bc01-4366-997c-8aa19baf4410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['[00:10] B: e',\n",
              "  '[00:33] B: could be a waiting room',\n",
              "  '[00:38] B: 2 chairs',\n",
              "  '[00:39] B: brown',\n",
              "  '[00:50] A: hey',\n",
              "  '[00:50] B: round table in the center with a plant on it',\n",
              "  \"[00:55] A: '/n\",\n",
              "  '[01:02] B: 3 lights on the wall',\n",
              "  '[01:08] B: the walls are beige',\n",
              "  '[01:10] A: I have flowers on table',\n",
              "  '[01:23] A: blue chairs',\n",
              "  '[01:26] B: you wish to find me or me find you'],\n",
              " '[01:31] A: I find you',\n",
              " 'Use',\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Undestanding Data:**\n",
        "\n",
        "Data looks like this:\n",
        "\n",
        "```\n",
        "[\n",
        "[[], \"[00:15] B: i'm in the playroom\", \"Initiate\", []],\n",
        "[[\"[00:15] B: i'm in the playroom\"], \"[00:17] B: you have to go west\", \"Initiate\", [0]],\n",
        "[[\"[00:15] B: i'm in the playroom\", \"[00:17] B: you have to go west\"], \"[00:19] A: What does it look like\", \"Use\", [1, 0]],\n",
        "[[\"[00:15] B: i'm in the playroom\", \"[00:17] B: you have to go west\"], \"[00:19] A: What does it look like\", \"Initiate\", [0, 0]],\n",
        "[[\"[00:15] B: i'm in the playroom\", \"[00:17] B: you have to go west\", \"[00:19] A: What does it look like\"], \"[00:38] A: describe it please\", \"Move\", [0, 1, 0]]\n",
        "]\n",
        "```\n",
        "\n",
        "As you can see there's an outer list A which contains a number of lists (B) of each data point which further contains a List C and D along with other elements. Let's understand B.\n",
        "\n",
        "```\n",
        "[[], \"[00:15] B: i'm in the playroom\", \"Initiate\", []]\n",
        "```\n",
        "\n",
        "In this list B, following are the elements:\n",
        "- `[]`: Context -> Utterances spoken so far in List C\n",
        "- `\"[00:15] B: i'm in the playroom\"`: Input -> Curent utterance\n",
        "-  `\"Initiate\"`: Grounding Act (at current stage)\n",
        "- `[]`: Reference to which element in context got grounded\n",
        "\n",
        "In context, we keep adding all the previous utterance which serve as context to current utterance in Input.\n",
        "\n",
        "Let's look at list B at 3rd index of A:\n",
        "```\n",
        "[[\"[00:15] B: i'm in the playroom\", \"[00:17] B: you have to go west\"], \"[00:19] A: What does it look like\", \"Use\", [1, 0]]\n",
        "```\n",
        "Here's what element means:\n",
        "- `[\"[00:15] B: i'm in the playroom\", \"[00:17] B: you have to go west\"]`: Context -> Utterances spoken so far\n",
        "- `\"[00:19] A: What does it look like\"`: Input -> Curent utterance\n",
        "-  `\"Use\"`: Grounding Act\n",
        "- `[1,0]`: 1st element in context (\"[00:15] B: i'm in the playroom\") got grounded with a Use"
      ],
      "metadata": {
        "id": "u1pdL-uYaOIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize then Merge"
      ],
      "metadata": {
        "id": "OisK9Ipil3Yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# or as per HuggingFace tutorial\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "2488a19793be4457b8d5ec0d0826fe4a",
            "38021d15612d4d45b79f7b3a3c85a9d8",
            "b5ef9b5a4afd48bfa1ba2f91de3bad79",
            "863edaf890414a9ca66c3212123ca4dd",
            "f08752f1d1cc44ee80ec805740d9a325",
            "ed564f95f14a4885b2ae0342ffc02b8a",
            "a9d13c4a52064a9989dcc913f60e9450",
            "c196487e8b674b4f9f3afd9eb4749c85",
            "75f8940b20f640caa27e07a6175fe3de",
            "f0907f99038d4e40b8b598e649ed3f80",
            "8203e0821b0f4002b7dfafb8586c9f39",
            "7a2aeda3399a4cdeb0a6f3ebb578669f",
            "d74d10517694451aa8ead2f9a817a0f7",
            "12a12a7e39904156a4520e4dd48b0186",
            "057bb92c40784dbe967547355a136a00",
            "0c9127c8c66844c3b35157d5486a7f45",
            "08e2f63c1cdc44308095018fe402ec10",
            "90a981422f7c434c952ce0f474159955",
            "6b93dc2f6c394de9bb2319400b83163d",
            "abab8023fcd946cd946e4484ca0c4a38",
            "8a84edb609fe463c9ca5ccd21d1f2bce",
            "8d0b6a6f4b3447cab497755433545b40",
            "58160ffe21664fb4a9d1442c8d330826",
            "ef3e397537b34ac7803f6c30d2b1b9cd",
            "277b6d7c11a2423fa821769ef9b89249",
            "2498a44bfd304c05976f913b9cb08214",
            "8dbc4f43cec74122b97796d6a7394d54",
            "08309ea9c6ec4eb79e46fa24ca3d9fe3",
            "9116000cb20a40ed817fe8846df49f70",
            "1abb65bd2c414b80b6617ca836562092",
            "612f26a615e641f79c5031b92f3a2117",
            "f57a62547fc34e41948f968ca4555ae5",
            "2abdab7994bb446bafb30a3cf6cee4ab"
          ]
        },
        "id": "nfwfS9oEqObN",
        "outputId": "a49aa83f-aeaf-4b8b-a1ff-8b0b06c19fbe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2488a19793be4457b8d5ec0d0826fe4a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a2aeda3399a4cdeb0a6f3ebb578669f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58160ffe21664fb4a9d1442c8d330826"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[[], \"[00:15] B: i'm in the playroom\", \"Initiate\", []],\n",
        "        [[\"[00:15] B: i'm in the playroom\"], \"[00:17] B: you have to go west\", \"Initiate\", [0]],\n",
        "        [[\"[00:15] B: i'm in the playroom\", \"[00:17] B: you have to go west\"], \"[00:19] A: What does it look like\", \"Use\", [1, 0]],\n",
        "        [[\"[00:15] B: i'm in the playroom\", \"[00:17] B: you have to go west\"], \"[00:19] A: What does it look like\", \"Initiate\", [0, 0]],\n",
        "        [[\"[00:15] B: i'm in the playroom\", \"[00:17] B: you have to go west\", \"[00:19] A: What does it look like\"], \"[00:38] A: describe it please\", \"Move\", [0, 1, 0]]]"
      ],
      "metadata": {
        "id": "a1CyJrx4l7EL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input for the Model:**\n",
        "\n",
        "We need to prepare input for the model in this format:\n",
        "\n",
        "      [All_Context [SEP] Input]\n",
        "\n",
        "But as know computers don't understand text but numbers so we will have to tokenize the data and get it ready."
      ],
      "metadata": {
        "id": "D24m_YMrfGZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenizing context:**\n",
        "\n",
        "Now, for tokenization:\n",
        "\n",
        "For each data list B, we individually tokenize each element in context and create its ```token_type_ids```. They will be set to 1 for the contexts which are grounded and for the rest they will be zero. And finally, we merge all individually tokenized elements into 1 list which represent B as whole.\n",
        "\n",
        "We use T5-Tokenizer to tokenize context. BERT and other models generate ```token_type_ids``` automatically when tokenizing but T5 doesn't. So, we have to manually create them.\n",
        "\n",
        "Here's how we create ```token_type_ids```:\n",
        "- One we have a list of each individually tokenized context i.e., each element of tokens_list represent tokens of each context in list C of List B. For example for the given context: ```[\"[00:15] B: i'm in the playroom\", \"[00:17] B: you have to go west\"]```\n",
        "  -\n",
        "```\"[00:15] B: i'm in the playroom\"``` will be tokenized separately and ```\"[00:17] B: you have to go west\"]``` separately.\n",
        "  - ```\"[00:15] B: i'm in the playroom\"```:\n",
        "          tensor([784, 1206, 10, 1808, 908, 272, 10, 3, 23, 31, 51, 16, 8, 577, 3082, 1])\n",
        "  - ```\"[00:17] B: you have to go west\"]```:\n",
        "          tensor([784, 1206, 10, 2517, 908, 272, 10, 25, 43, 12, 281, 4653, 1])\n",
        "  - ```tokens_list``` = containing both the contexts as\n",
        "          tokens_list:\n",
        "          [{'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
        "            8,  577, 3082,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])},\n",
        "            \n",
        "            {'input_ids': tensor([[ 784, 1206,   10, 2517,  908,  272,   10,   25,   43,   12,  281, 4653,\n",
        "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}]"
      ],
      "metadata": {
        "id": "SbKR-2dMc3ia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Token_type_ids:**\n",
        "This tokenization is currently missing ```token_type_ids```. We manually create them.\n",
        "\n",
        "- We generate a list ```token_type_id``` of all zeros initially. Inside, it has the same number of lists as ```token_type_ids``` and each list should be of the same corresponding size as well. Basically, we each context tokenized in ```token_type_ids```, we want to have another list either containing all 1s or all 0s to represent if this context was grounded or not.  For the same List B and its contexts as considered before:\n",
        "          token_type_id:  [tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])]\n",
        "\n",
        "- Now, we need only need to set that element 1 which corresponds to the grounded context in ```token_type_ids```. This is given by the last element of list B i.e., ```[1, 0]```. Hence, we store last index in ```grounded_context_list```.\n",
        "         grounded_context_list: [1, 0]]\n",
        "    \n",
        "- It is supposed to be the same size as number of contexts in list C of List B, which generates a list of same size called ```token_type_ids``` corresponding to which we generate ```token_type_id```. Since all of them are in sync with their indices and contents at the indices, whichever index is 1 in ```grounded_context_list```, we set the elements of the corresponding index in ```token_type_id``` as 1.\n",
        "          token_type_id:  [tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])]"
      ],
      "metadata": {
        "id": "kiCDIvRDlzog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Result of Tokenized Context:**\n",
        "\n",
        "Now that we have tokenized context\n",
        "          \n",
        "          tokens_list:\n",
        "          [{'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
        "            8,  577, 3082,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])},\n",
        "            \n",
        "            {'input_ids': tensor([[ 784, 1206,   10, 2517,  908,  272,   10,   25,   43,   12,  281, 4653,\n",
        "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}]\n",
        "and  their corresponding token_type_ids:\n",
        "\n",
        "          token_type_id:  [tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])]\n",
        "\n",
        "We need to add each element of ```token_typy_id``` to its corresponding tokenized context in ```tokens_list```.\n",
        "\n",
        "As we can see, ```tokens_list``` is a list of dictionaries. Each element of dictionary representing information of a context having key and value pairs for ```input_ids``` and ```attention_mask```. To this, we need to add one more key ```token_type_ids``` and get the value from  ```token_type_id```.\n",
        "\n",
        "<br>\n",
        "\n",
        "Now that we have finished making a complete list for each context in list C of list B having all the contents needed for tokenized context i.e., ```input_ids```, ```attention_masks```, ```token_type_ids```, we keep adding this final product to ```tokenized_contexts```.\n",
        "\n",
        "          [\n",
        "            {'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
        "            8,  577, 3082,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])},\n",
        "            \n",
        "            {'input_ids': tensor([[ 784, 1206,   10, 2517,  908,  272,   10,   25,   43,   12,  281, 4653,\n",
        "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
        "            ]  "
      ],
      "metadata": {
        "id": "M20wxACFl3LB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input id, attention mask, token type id for each context\n",
        "# data = [[[], \"[00:15] B: i'm in the playroom\", \"Initiate\", []],\n",
        "#         [[\"[00:15] B: i'm in the playroom\"], \"[00:17] B: you have to go west\", \"Initiate\", [0]],\n",
        "#         [[\"[00:15] B: i'm in the playroom\", \"[00:17] B: you have to go west\"], \"[00:19] A: What does it look like\", \"Use\", [1, 0]]\n",
        "# ]\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    tokenized_contexts = []\n",
        "\n",
        "    for idx, item in enumerate(examples):\n",
        "        token_type_ids = {}\n",
        "        tokens_list = [tokenizer(context, padding=True, truncation=True, return_tensors=\"pt\") for context in item[0]]\n",
        "        #print('\\n', '\\n token list: ', tokens_list)\n",
        "\n",
        "        # Create a list `token_type_id` with the same number of lists and sizes as `input_ids`\n",
        "        token_type_id = [torch.zeros_like(tokens['input_ids']) for tokens in tokens_list]\n",
        "        #print('token_type_id: ', token_type_id)\n",
        "\n",
        "        grounded_context_list = item[-1]\n",
        "\n",
        "        # Go over list of grounded_context_list and whichever index is 1, set the corresponding element in token_type_id = 1\n",
        "        for i, grounded_context in enumerate(grounded_context_list):\n",
        "            current_token_type_id = token_type_id[i]\n",
        "            if grounded_context == 1:\n",
        "                current_token_type_id[current_token_type_id == 0] = 1\n",
        "\n",
        "        #print('token_type_id: ', token_type_id)\n",
        "\n",
        "        # Store the token_type_ids in the token_type_ids dictionary with the key as the index\n",
        "        token_type_ids['token_type_ids'] = token_type_id\n",
        "\n",
        "        # For each token_type_id\n",
        "        for j,id in enumerate(token_type_id):\n",
        "            current_content = tokens_list[j] # get the corresponding element having context tokens -> it will be dictionary {'input_ids': tensor([[ 784, 1206,...]]), 'attention_mask': tensor([[1, 1, ...]])}\n",
        "            current_content['token_type_ids'] = id # to this dictionary add another key 'token_type_ids' and add value as the current token_type_id stored in 'id'\n",
        "\n",
        "        # Finally keep adding the prepared tokens_list elements to final tokenized_contexts as we go\n",
        "        tokenized_contexts.append(tokens_list)\n",
        "        #print('tokenized context: ', tokenized_contexts)\n",
        "\n",
        "    return tokenized_contexts, token_type_ids\n",
        "\n",
        "# Tokenize each element in item[0] separately i.e., each context\n",
        "tokenized_data, token_type_ids = preprocess_function(data)\n",
        "\n",
        "# Print the tokenized data and token_type_ids\n",
        "# for i, tokens_list in enumerate(tokenized_data):\n",
        "#     print(\"----------------------------------------------------------------------------------------------------------------\")\n",
        "#     print(f\"Example {i + 1}:\")\n",
        "#     for j, tokens in enumerate(tokens_list):\n",
        "#         print(f\"  Tokens {j + 1}:\", tokenizer.convert_ids_to_tokens(tokens['input_ids'][0]))\n",
        "#         print(f\"  Input IDs {j + 1}:\", tokens['input_ids'][0])\n",
        "#     #print(f\"  Token Type IDs:\", token_type_ids[i])\n",
        "\n",
        "#     print()\n",
        "\n",
        "for i in tokenized_data:\n",
        "    print(i,'\\n')\n",
        "\n",
        "#print(tokenized_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjvgnELE1uma",
        "outputId": "9654e61b-a6cb-483b-ce99-f40d81ec21bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[] \n",
            "\n",
            "[{'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
            "            8,  577, 3082,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}] \n",
            "\n",
            "[{'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
            "            8,  577, 3082,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[ 784, 1206,   10, 2517,  908,  272,   10,   25,   43,   12,  281, 4653,\n",
            "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}] \n",
            "\n",
            "[{'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
            "            8,  577, 3082,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}, {'input_ids': tensor([[ 784, 1206,   10, 2517,  908,  272,   10,   25,   43,   12,  281, 4653,\n",
            "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}] \n",
            "\n",
            "[{'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
            "            8,  577, 3082,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}, {'input_ids': tensor([[ 784, 1206,   10, 2517,  908,  272,   10,   25,   43,   12,  281, 4653,\n",
            "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[ 784, 1206,   10, 2294,  908,   71,   10,  363,  405,   34,  320,  114,\n",
            "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now ```tokenized_data``` contains each context tokenized separately. For example in:\n",
        "\n",
        "        [[\"[00:15] B: i'm in the playroom\", \"[00:17] B: you have to go west\"], \"[00:19] A: What does it look like\", \"Use\", [1, 0]]\n",
        "\n",
        "```\"[00:15] B: i'm in the playroom\"``` is tokenized separately\n",
        "\n",
        "        {'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
        "            8,  577, 3082,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
        "\n",
        "and ```\"[00:17] B: you have to go west\"]``` separately as\n",
        "\n",
        "           {'input_ids': tensor([[ 784, 1206,   10, 2517,  908,  272,   10,   25,   43,   12,  281, 4653,\n",
        "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
        "\n",
        "They are stored together in ```tokenized_list``` but separated by commas.\n",
        "\n",
        "          [{'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
        "            8,  577, 3082,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])},\n",
        "            \n",
        "            {'input_ids': tensor([[ 784, 1206,   10, 2517,  908,  272,   10,   25,   43,   12,  281, 4653,\n",
        "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}]\n",
        "\n",
        "\n",
        "Now, we want to have all the contexts together. For one data point, i.e.,List C of List B, instead of\n",
        "          \n",
        "          [context, context]\n",
        "we want\n",
        "\n",
        "          [context]\n",
        "\n",
        "So, we merge all the information for one data point i.e., List B into 1. We dissolve List C. and now instead of 1,2 or whatever number of contexts separately, we will have one huge context based on only one ```input_ids```, ```attention_masks``` and ```token_type_ids```.\n",
        "\n",
        "        {'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
        "            8,  577, 3082,    1,  784, 1206,   10, 2517,  908,  272,   10,   25,\n",
        "           43,   12,  281, 4653,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "         1, 1, 1, 1, 1]]), 'token_type_ids:': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "         0, 0, 0, 0, 0]])}\n"
      ],
      "metadata": {
        "id": "xDLw5kcXDkYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# merging context\n",
        "\n",
        "# Initialize a list to store the merged tokens (input IDs and attention masks)\n",
        "merged_tokens = []\n",
        "\n",
        "# Iterate through each element in tokenized_data\n",
        "for example in tokenized_data:\n",
        "\n",
        "    # Initialize lists to store input IDs and attention masks for each element in the example\n",
        "    input_ids_list = []\n",
        "    attention_mask_list = []\n",
        "    token_type_ids_list = []\n",
        "\n",
        "    # Iterate through each part in the example\n",
        "    for part in example:\n",
        "\n",
        "        # Extract the input IDs and attention masks from the part\n",
        "        input_ids = part['input_ids']\n",
        "        attention_mask = part['attention_mask']\n",
        "        token_type = part['token_type_ids']\n",
        "\n",
        "        # Append the input IDs and attention masks to their respective lists\n",
        "        input_ids_list.append(input_ids)\n",
        "        attention_mask_list.append(attention_mask)\n",
        "        token_type_ids_list.append(token_type)\n",
        "\n",
        "    # Check if the input IDs list is empty. If empty, create a single tensor with the shape (1, 1) containing a special token ID.\n",
        "    if not input_ids_list:\n",
        "        input_ids_list.append(torch.tensor([[tokenizer.pad_token_id]]))\n",
        "        attention_mask_list.append(torch.tensor([[0]]))\n",
        "        token_type_ids_list.append(torch.tensor([[0]]))\n",
        "\n",
        "    # Concatenate the input IDs and attention masks along the last dimension (dimension 1) to create merged tensors\n",
        "    merged_input_ids = torch.cat(input_ids_list, dim=1)\n",
        "    merged_attention_mask = torch.cat(attention_mask_list, dim=1)\n",
        "    merged_token_type_ids = torch.cat(token_type_ids_list, dim=1)\n",
        "\n",
        "    # Create a dictionary with the merged input IDs and attention masks\n",
        "    merged_example = {'input_ids': merged_input_ids, 'attention_mask': merged_attention_mask, 'token_type_ids:': merged_token_type_ids}\n",
        "\n",
        "    # Append the merged_example dictionary to the merged_tokens list\n",
        "    merged_tokens.append(merged_example)\n",
        "\n",
        "# Print the merged tokens and attention masks together\n",
        "for i, example in enumerate(merged_tokens):\n",
        "    print(f\"Example {i + 1} - Merged Tokens and Attention Mask: {example}\")\n",
        "    print()\n",
        "\n",
        "#print(merged_tokens, type(merged_tokens))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPDLTYQ1gazq",
        "outputId": "d0ee88ed-2611-4094-edea-cf27fe756b59"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 - Merged Tokens and Attention Mask: {'input_ids': tensor([[0]]), 'attention_mask': tensor([[0]]), 'token_type_ids:': tensor([[0]])}\n",
            "\n",
            "Example 2 - Merged Tokens and Attention Mask: {'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
            "            8,  577, 3082,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids:': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
            "\n",
            "Example 3 - Merged Tokens and Attention Mask: {'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
            "            8,  577, 3082,    1,  784, 1206,   10, 2517,  908,  272,   10,   25,\n",
            "           43,   12,  281, 4653,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1]]), 'token_type_ids:': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]])}\n",
            "\n",
            "Example 4 - Merged Tokens and Attention Mask: {'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
            "            8,  577, 3082,    1,  784, 1206,   10, 2517,  908,  272,   10,   25,\n",
            "           43,   12,  281, 4653,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1]]), 'token_type_ids:': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]])}\n",
            "\n",
            "Example 5 - Merged Tokens and Attention Mask: {'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
            "            8,  577, 3082,    1,  784, 1206,   10, 2517,  908,  272,   10,   25,\n",
            "           43,   12,  281, 4653,    1,  784, 1206,   10, 2294,  908,   71,   10,\n",
            "          363,  405,   34,  320,  114,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids:': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(merged_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUVvzhjRSYcj",
        "outputId": "948095b2-cf1f-4812-df0f-bd0c98c5e93c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merging input and its token_type_ids to merged_tokens list"
      ],
      "metadata": {
        "id": "PecNUpUjaT8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input id, attention mask, token type id for each context\n",
        "# data = [[[], \"[00:15] B: i'm in the playroom\", \"Initiate\", []],\n",
        "#         [[\"[00:15] B: i'm in the playroom\"], \"[00:17] B: you have to go west\", \"Initiate\", [0]],\n",
        "#         [[\"[00:15] B: i'm in the playroom\", \"[00:17] B: you have to go west\"], \"[00:19] A: What does it look like\", \"Use\", [1, 0]]\n",
        "# ]\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    tokenized_contexts = []\n",
        "\n",
        "    for idx, item in enumerate(examples):\n",
        "        token_type_ids = {}\n",
        "        tokens_list = [tokenizer(context, padding=True, truncation=True, return_tensors=\"pt\") for context in item[0]]\n",
        "        #print('\\n', '\\n token list: ', tokens_list)\n",
        "\n",
        "        # Create a list `token_type_id` with the same number of lists and sizes as `input_ids`\n",
        "        token_type_id = [torch.zeros_like(tokens['input_ids']) for tokens in tokens_list]\n",
        "        #print('token_type_id: ', token_type_id)\n",
        "\n",
        "        grounded_context_list = item[-1]\n",
        "\n",
        "        # Go over list of grounded_context_list and whichever index is 1, set the corresponding element in token_type_id = 1\n",
        "        for i, grounded_context in enumerate(grounded_context_list):\n",
        "            current_token_type_id = token_type_id[i]\n",
        "            if grounded_context == 1:\n",
        "                current_token_type_id[current_token_type_id == 0] = 1\n",
        "\n",
        "        #print('token_type_id: ', token_type_id)\n",
        "\n",
        "        # Store the token_type_ids in the token_type_ids dictionary with the key as the index\n",
        "        token_type_ids['token_type_ids'] = token_type_id\n",
        "\n",
        "        # For each token_type_id\n",
        "        for j,id in enumerate(token_type_id):\n",
        "            current_content = tokens_list[j] # get the corresponding element having context tokens -> it will be dictionary {'input_ids': tensor([[ 784, 1206,...]]), 'attention_mask': tensor([[1, 1, ...]])}\n",
        "            current_content['token_type_ids'] = id # to this dictionary add another key 'token_type_ids' and add value as the current token_type_id stored in 'id'\n",
        "\n",
        "        # Finally keep adding the prepared tokens_list elements to final tokenized_contexts as we go\n",
        "        tokenized_contexts.append(tokens_list)\n",
        "        #print('tokenized context: ', tokenized_contexts)\n",
        "\n",
        "    return tokenized_contexts, token_type_ids\n",
        "\n",
        "# Tokenize each element in item[0] separately i.e., each context\n",
        "tokenized_data, token_type_ids = preprocess_function(data)\n",
        "\n",
        "# Print the tokenized data and token_type_ids\n",
        "# for i, tokens_list in enumerate(tokenized_data):\n",
        "#     print(\"----------------------------------------------------------------------------------------------------------------\")\n",
        "#     print(f\"Example {i + 1}:\")\n",
        "#     for j, tokens in enumerate(tokens_list):\n",
        "#         print(f\"  Tokens {j + 1}:\", tokenizer.convert_ids_to_tokens(tokens['input_ids'][0]))\n",
        "#         print(f\"  Input IDs {j + 1}:\", tokens['input_ids'][0])\n",
        "#     #print(f\"  Token Type IDs:\", token_type_ids[i])\n",
        "\n",
        "#     print()\n",
        "\n",
        "# for i in tokenized_data:\n",
        "#     print(i,'\\n')\n",
        "\n",
        "print(tokenized_data)\n"
      ],
      "metadata": {
        "id": "RU-Nm0GJaW29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57a38fee-72f4-44d9-b4c8-a1f2831c8fbf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[], [{'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
            "            8,  577, 3082,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}], [{'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
            "            8,  577, 3082,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[ 784, 1206,   10, 2517,  908,  272,   10,   25,   43,   12,  281, 4653,\n",
            "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}], [{'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
            "            8,  577, 3082,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}, {'input_ids': tensor([[ 784, 1206,   10, 2517,  908,  272,   10,   25,   43,   12,  281, 4653,\n",
            "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}], [{'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
            "            8,  577, 3082,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}, {'input_ids': tensor([[ 784, 1206,   10, 2517,  908,  272,   10,   25,   43,   12,  281, 4653,\n",
            "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[ 784, 1206,   10, 2294,  908,   71,   10,  363,  405,   34,  320,  114,\n",
            "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}], [{'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
            "            8,  577, 3082,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}, {'input_ids': tensor([[ 784, 1206,   10, 2517,  908,  272,   10,   25,   43,   12,  281, 4653,\n",
            "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}, {'input_ids': tensor([[ 784, 1206,   10, 2294,  908,   71,   10,  363,  405,   34,  320,  114,\n",
            "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[ 784, 1206,   10, 3747,  908,   71,   10, 5530,   34,  754,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[  784,  1206,    10,  3769,   908,    71,    10,    27,    31,    51,\n",
            "            16,    80,    38,   168,     6,    27,   217,     3,     9,   422,\n",
            "         22382,  1976,    16,     8,  2752,    11,     3,     9,   422,  5748,\n",
            "            12,     8,   269,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing input and generating token_type_ids for it"
      ],
      "metadata": {
        "id": "fAPDaM2jrke4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "input_tokens_list = []\n",
        "for item in data:\n",
        "    tokens = tokenizer(item[1], padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    input_tokens_list.append(tokens)\n",
        "\n",
        "# Create a list of all ones with the same size as tokens_list\n",
        "input_token_type_ids = [torch.ones_like(input['input_ids']) for input in input_tokens_list]\n",
        "\n",
        "# Print the tokenized elements and token_type_ids\n",
        "for i, input_tokens in enumerate(input_tokens_list):\n",
        "    print(f\"Example {i + 1} - Tokens:\", tokenizer.convert_ids_to_tokens(input_tokens['input_ids'][0]))\n",
        "    print(f\"          - Token Type IDs:\", input_token_type_ids[i][0],'\\n')\n",
        "\n",
        "print(input_tokens_list)\n",
        "print(input_token_type_ids)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o85gLW76Uv-G",
        "outputId": "1af5e6fc-2670-413a-e501-7f2bcba9faba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 - Tokens: ['▁[', '00', ':', '15', ']', '▁B', ':', '▁', 'i', \"'\", 'm', '▁in', '▁the', '▁play', 'room', '</s>']\n",
            "          - Token Type IDs: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) \n",
            "\n",
            "Example 2 - Tokens: ['▁[', '00', ':', '17', ']', '▁B', ':', '▁you', '▁have', '▁to', '▁go', '▁west', '</s>']\n",
            "          - Token Type IDs: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) \n",
            "\n",
            "Example 3 - Tokens: ['▁[', '00', ':', '19', ']', '▁A', ':', '▁What', '▁does', '▁it', '▁look', '▁like', '</s>']\n",
            "          - Token Type IDs: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) \n",
            "\n",
            "Example 4 - Tokens: ['▁[', '00', ':', '19', ']', '▁A', ':', '▁What', '▁does', '▁it', '▁look', '▁like', '</s>']\n",
            "          - Token Type IDs: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) \n",
            "\n",
            "Example 5 - Tokens: ['▁[', '00', ':', '38', ']', '▁A', ':', '▁describe', '▁it', '▁please', '</s>']\n",
            "          - Token Type IDs: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) \n",
            "\n",
            "Example 6 - Tokens: ['▁[', '01', ':', '39', ']', '▁A', ':', '▁Please', '▁describe', '▁what', '▁you', '▁see', '▁in', '▁your', '▁play', 'room', '</s>']\n",
            "          - Token Type IDs: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) \n",
            "\n",
            "[{'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
            "            8,  577, 3082,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[ 784, 1206,   10, 2517,  908,  272,   10,   25,   43,   12,  281, 4653,\n",
            "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[ 784, 1206,   10, 2294,  908,   71,   10,  363,  405,   34,  320,  114,\n",
            "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[ 784, 1206,   10, 2294,  908,   71,   10,  363,  405,   34,  320,  114,\n",
            "            1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[ 784, 1206,   10, 3747,  908,   71,   10, 5530,   34,  754,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[ 784, 4542,   10, 3288,  908,   71,   10,  863, 5530,  125,   25,  217,\n",
            "           16,   39,  577, 3082,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}]\n",
            "[tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merging all the individual contexts per data point into 1 per data point.\n",
        "\n",
        "Then adding -1 for [SEP] to all input_ids, attention_mask and token_type_ids\n",
        "\n",
        "Finally, adding all the relevant tokens for input after [SEP]"
      ],
      "metadata": {
        "id": "p1RexxLmrrbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# merging context adding [SEP] and adding input\n",
        "\n",
        "# Initialize a list to store the merged tokens (input IDs and attention masks)\n",
        "merged_tokens = []\n",
        "\n",
        "# Iterate through each element in tokenized_data\n",
        "for index,example in enumerate(tokenized_data):\n",
        "\n",
        "    # Initialize lists to store input IDs and attention masks for each element in the example\n",
        "    input_ids_list = []\n",
        "    attention_mask_list = []\n",
        "    token_type_ids_list = []\n",
        "\n",
        "\n",
        "\n",
        "    # Iterate through each part in the example\n",
        "    for part in example:\n",
        "\n",
        "        # Extract the input IDs and attention masks from the part\n",
        "        input_ids = part['input_ids']\n",
        "        attention_mask = part['attention_mask']\n",
        "        token_type = part['token_type_ids']\n",
        "\n",
        "        # Append the input IDs and attention masks to their respective lists\n",
        "        input_ids_list.append(input_ids)\n",
        "        attention_mask_list.append(attention_mask)\n",
        "        token_type_ids_list.append(token_type)\n",
        "\n",
        "    # Check if the input IDs list is empty. If empty, create a single tensor with the shape (1, 1) containing a special token ID.\n",
        "    if not input_ids_list:\n",
        "        input_ids_list.append(torch.tensor([[tokenizer.pad_token_id]]))\n",
        "        attention_mask_list.append(torch.tensor([[0]]))\n",
        "        token_type_ids_list.append(torch.tensor([[0]]))\n",
        "\n",
        "    # Concatenate the input IDs and attention masks along the last dimension (dimension 1) to create merged tensors\n",
        "    merged_input_ids = torch.cat(input_ids_list, dim=1)\n",
        "    merged_attention_mask = torch.cat(attention_mask_list, dim=1)\n",
        "    merged_token_type_ids = torch.cat(token_type_ids_list, dim=1)\n",
        "\n",
        "\n",
        "    # Add -1 at the end of each merged tensor to represent [SEP] after which we will add tokenized input\n",
        "    merged_input_ids = torch.cat([merged_input_ids, torch.tensor([[-1]])], dim=1)\n",
        "    merged_attention_mask = torch.cat([merged_attention_mask, torch.tensor([[-1]])], dim=1)\n",
        "    merged_token_type_ids = torch.cat([merged_token_type_ids, torch.tensor([[-1]])], dim=1)\n",
        "\n",
        "    #Extract from input_tokens_list\n",
        "    # Access the corresponding dictionary in input_tokens_list using the index 'idx'\n",
        "    current_dict = input_tokens_list[index]\n",
        "\n",
        "    # Now you can use 'current_dict' which corresponds to the current element in the external loop\n",
        "    input_id = current_dict['input_ids']\n",
        "    input_attention = current_dict['attention_mask']\n",
        "\n",
        "    # Add all the required tokens for tokenized input after -1 i.e., [SEP]\n",
        "    # Add all the required tokens for tokenized input after -1 i.e., [SEP]\n",
        "    merged_input_ids = torch.cat((merged_input_ids, input_id), dim=1)\n",
        "    merged_attention_mask = torch.cat((merged_attention_mask, input_attention), dim=1)\n",
        "    merged_token_type_ids = torch.cat((merged_token_type_ids, input_token_type_ids[index]), dim=1)\n",
        "\n",
        "\n",
        "    # Create a dictionary with the merged input IDs and attention masks\n",
        "    merged_example = {'input_ids': merged_input_ids, 'attention_mask': merged_attention_mask, 'token_type_ids:': merged_token_type_ids}\n",
        "\n",
        "    # Append the merged_example dictionary to the merged_tokens list\n",
        "    merged_tokens.append(merged_example)\n",
        "\n",
        "# Print the merged tokens and attention masks together\n",
        "for i, example in enumerate(merged_tokens):\n",
        "    print(f\"Example {i + 1} - Merged Tokens and Attention Mask: {example}\")\n",
        "    print()\n",
        "\n",
        "#print(merged_tokens, type(merged_tokens))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnlnwCwUpryf",
        "outputId": "e7230652-920c-427f-f442-04a4f5bdeebc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 - Merged Tokens and Attention Mask: {'input_ids': tensor([[   0,   -1,  784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,\n",
            "           51,   16,    8,  577, 3082,    1]]), 'attention_mask': tensor([[ 0, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]]), 'token_type_ids:': tensor([[ 0, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]])}\n",
            "\n",
            "Example 2 - Merged Tokens and Attention Mask: {'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
            "            8,  577, 3082,    1,   -1,  784, 1206,   10, 2517,  908,  272,   10,\n",
            "           25,   43,   12,  281, 4653,    1]]), 'attention_mask': tensor([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]]), 'token_type_ids:': tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]])}\n",
            "\n",
            "Example 3 - Merged Tokens and Attention Mask: {'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
            "            8,  577, 3082,    1,  784, 1206,   10, 2517,  908,  272,   10,   25,\n",
            "           43,   12,  281, 4653,    1,   -1,  784, 1206,   10, 2294,  908,   71,\n",
            "           10,  363,  405,   34,  320,  114,    1]]), 'attention_mask': tensor([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1]]), 'token_type_ids:': tensor([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1]])}\n",
            "\n",
            "Example 4 - Merged Tokens and Attention Mask: {'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
            "            8,  577, 3082,    1,  784, 1206,   10, 2517,  908,  272,   10,   25,\n",
            "           43,   12,  281, 4653,    1,   -1,  784, 1206,   10, 2294,  908,   71,\n",
            "           10,  363,  405,   34,  320,  114,    1]]), 'attention_mask': tensor([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1]]), 'token_type_ids:': tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1]])}\n",
            "\n",
            "Example 5 - Merged Tokens and Attention Mask: {'input_ids': tensor([[ 784, 1206,   10, 1808,  908,  272,   10,    3,   23,   31,   51,   16,\n",
            "            8,  577, 3082,    1,  784, 1206,   10, 2517,  908,  272,   10,   25,\n",
            "           43,   12,  281, 4653,    1,  784, 1206,   10, 2294,  908,   71,   10,\n",
            "          363,  405,   34,  320,  114,    1,   -1,  784, 1206,   10, 3747,  908,\n",
            "           71,   10, 5530,   34,  754,    1]]), 'attention_mask': tensor([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]]), 'token_type_ids:': tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]])}\n",
            "\n",
            "Example 6 - Merged Tokens and Attention Mask: {'input_ids': tensor([[  784,  1206,    10,  1808,   908,   272,    10,     3,    23,    31,\n",
            "            51,    16,     8,   577,  3082,     1,   784,  1206,    10,  2517,\n",
            "           908,   272,    10,    25,    43,    12,   281,  4653,     1,   784,\n",
            "          1206,    10,  2294,   908,    71,    10,   363,   405,    34,   320,\n",
            "           114,     1,   784,  1206,    10,  3747,   908,    71,    10,  5530,\n",
            "            34,   754,     1,   784,  1206,    10,  3769,   908,    71,    10,\n",
            "            27,    31,    51,    16,    80,    38,   168,     6,    27,   217,\n",
            "             3,     9,   422, 22382,  1976,    16,     8,  2752,    11,     3,\n",
            "             9,   422,  5748,    12,     8,   269,     1,    -1,   784,  4542,\n",
            "            10,  3288,   908,    71,    10,   863,  5530,   125,    25,   217,\n",
            "            16,    39,   577,  3082,     1]]), 'attention_mask': tensor([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]]), 'token_type_ids:': tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]])}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Output"
      ],
      "metadata": {
        "id": "VRdhOQoxsCzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# List of actions\n",
        "acts = ['Use', 'Move', 'Req-Ack', 'Req-Repair', 'Repair', 'Initiate', 'Ack-Req-Ack', 'Repeat', 'Explicit-Ack', 'Continue', 'Repeat-Back', 'Cancel']\n",
        "\n",
        "# Given data\n",
        "data = [[[], \"[00:15] B: i'm in the playroom\", \"Initiate\", []],\n",
        "        [[\"[00:15] B: i'm in the playroom\"], \"[00:17] B: you have to go west\", \"Initiate\", [0]],\n",
        "        [[\"[00:15] B: i'm in the playroom\", \"[00:17] B: you have to go west\"], \"[00:19] A: What does it look like\", \"Use\", [1, 0]],\n",
        "        [[\"[00:15] B: i'm in the playroom\", \"[00:17] B: you have to go west\"], \"[00:19] A: What does it look like\", \"Initiate\", [0, 0]],\n",
        "        [[\"[00:15] B: i'm in the playroom\", \"[00:17] B: you have to go west\", \"[00:19] A: What does it look like\"], \"[00:38] A: describe it please\", \"Move\", [0, 1, 0]],\n",
        "        [[\"[00:15] B: i'm in the playroom\", \"[00:17] B: you have to go west\", \"[00:19] A: What does it look like\", \"[00:38] A: describe it please\", \"[00:55] A: I'm in one as well, I see  a small chalkboard in the corner and a small tent to the right\"], \"[01:39] A: Please describe what you see in your playroom\", \"Repeat\", [0, 0, 1, 1, 0]]]\n",
        "\n",
        "# Initialize the LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(acts)\n",
        "\n",
        "# Initialize the output list\n",
        "output = []\n",
        "\n",
        "# Iterate through each list B in the data\n",
        "for idx, item in enumerate(data):\n",
        "    # Get the actions list from the 3rd element of list B\n",
        "    actions = item[2]\n",
        "    #print('\\nactions: ', actions)\n",
        "    # Convert the actions to a 1-dimensional array and then encode using LabelEncoder\n",
        "    encoded_actions = label_encoder.transform([actions])[0]\n",
        "    #print(\"encoded: \", encoded_actions)\n",
        "    output.append(encoded_actions)\n",
        "\n",
        "# Print the encoded actions for each list B\n",
        "for i, encoded_actions in enumerate(output):\n",
        "    print(f\"\\nExample {i + 1} - Encoded Actions: {encoded_actions}\")\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqOHY0iVxEkz",
        "outputId": "c2bac05c-fdfe-4ae7-992e-dffbe933fadc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example 1 - Encoded Actions: 4\n",
            "\n",
            "Example 2 - Encoded Actions: 4\n",
            "\n",
            "Example 3 - Encoded Actions: 11\n",
            "\n",
            "Example 4 - Encoded Actions: 4\n",
            "\n",
            "Example 5 - Encoded Actions: 5\n",
            "\n",
            "Example 6 - Encoded Actions: 7\n",
            "[4, 4, 11, 4, 5, 7]\n"
          ]
        }
      ]
    }
  ]
}